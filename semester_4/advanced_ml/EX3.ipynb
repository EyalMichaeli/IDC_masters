{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part 0: Choose pretrained image classification model and images to be explained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We chose to use VGG16. We will download it pretrained and establish its performance on 100 images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import requests\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:42:44.768042600Z",
     "start_time": "2023-06-13T10:42:44.742216200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:09:53.070286400Z",
     "start_time": "2023-06-13T10:09:52.115404700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2 images from the cat category:\n",
      "Downloaded: imagenet_subset\\cat\\cat_0.png\n",
      "Downloading 2 images from the dog category:\n",
      "Downloaded: imagenet_subset\\dog\\dog_0.png\n",
      "Downloading 2 images from the bird category:\n",
      "Downloaded: imagenet_subset\\bird\\bird_0.png\n",
      "Downloading 2 images from the turtle category:\n",
      "Downloaded: imagenet_subset\\turtle\\turtle_0.png\n"
     ]
    }
   ],
   "source": [
    "# Define the URL to download the ImageNet images\n",
    "url = \"http://image-net.org/image/\"\n",
    "\n",
    "# Define the subset of categories to download\n",
    "categories = [\"cat\", \"dog\", \"bird\", \"turtle\"]  # Example categories\n",
    "\n",
    "# Define the output directory to store the downloaded images\n",
    "output_dir = \"imagenet_subset\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Download the images for each category\n",
    "for category in categories:\n",
    "    category_dir = os.path.join(output_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "\n",
    "    # Download a fixed number of images per category\n",
    "    # num_images_per_category = 26 if category != \"cat\" else 25\n",
    "    num_images_per_category = 2\n",
    "    print(f\"Downloading {num_images_per_category} images from the {category} category:\")\n",
    "    for i in range(num_images_per_category):\n",
    "        image_url = f\"{url}/{category}/{category}_{i}.png\"\n",
    "        image_path = os.path.join(category_dir, f\"{category}_{i}.png\")\n",
    "\n",
    "        # Download the image\n",
    "        response = requests.get(image_url)\n",
    "\n",
    "        # Save the image to the specified directory\n",
    "        with open(image_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Downloaded: {image_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:25:31.665272500Z",
     "start_time": "2023-06-13T10:25:20.544749900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Define the path to the directory containing the images\n",
    "image_dir = \"imagenet_subset\"\n",
    "\n",
    "# Define the path to save the model weights (if necessary)\n",
    "\n",
    "# Define the number of images to evaluate\n",
    "num_images = 100\n",
    "\n",
    "# Define the batch size for evaluation\n",
    "batch_size = 16\n",
    "\n",
    "# Define the transformation for preprocessing the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create the dataset and data loader\n",
    "dataset = ImageFolder(image_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:20:12.971785300Z",
     "start_time": "2023-06-13T10:20:12.950707500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 103\n    Root location: imagenet_subset\n    StandardTransform\nTransform: Compose(\n               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n               ToTensor()\n               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n           )"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:20:55.657656800Z",
     "start_time": "2023-06-13T10:20:55.652658200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BufferedReader name='imagenet_subset\\\\bird\\\\bird_0.jpg'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m predicted_labels \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Iterate over the batches of images\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, _ \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# Forward pass through the model\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(images)\n\u001B[0;32m      8\u001B[0m     _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    679\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 681\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    684\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    685\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    719\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    720\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 721\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    722\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    723\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py:230\u001B[0m, in \u001B[0;36mDatasetFolder.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;124;03m    index (int): Index\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001B[39;00m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    229\u001B[0m path, target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[index]\n\u001B[1;32m--> 230\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    232\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(sample)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py:269\u001B[0m, in \u001B[0;36mdefault_loader\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accimage_loader(path)\n\u001B[0;32m    268\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 269\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpil_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py:248\u001B[0m, in \u001B[0;36mpil_loader\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpil_loader\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Image\u001B[38;5;241m.\u001B[39mImage:\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001B[39;00m\n\u001B[0;32m    247\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m--> 248\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    249\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m img\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py:3283\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3281\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message)\n\u001B[0;32m   3282\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot identify image file \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (filename \u001B[38;5;28;01mif\u001B[39;00m filename \u001B[38;5;28;01melse\u001B[39;00m fp)\n\u001B[1;32m-> 3283\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m UnidentifiedImageError(msg)\n",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m: cannot identify image file <_io.BufferedReader name='imagenet_subset\\\\bird\\\\bird_0.jpg'>"
     ]
    }
   ],
   "source": [
    "# Define a list to store the predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate over the batches of images\n",
    "for images, _ in dataloader:\n",
    "    # Forward pass through the model\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Append the predicted labels to the list\n",
    "    predicted_labels.extend(predicted.tolist())\n",
    "\n",
    "# Get the predicted labels for the evaluated images\n",
    "evaluated_labels = predicted_labels[:num_images]\n",
    "\n",
    "# Print the predicted labels for the evaluated images\n",
    "print(\"Predicted labels for the evaluated images:\")\n",
    "print(evaluated_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:22:38.182900800Z",
     "start_time": "2023-06-13T10:22:38.125887800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'imagenet_subset\\\\bird\\\\bird_0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimagenet_subset\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mbird\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mbird_0.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py:3283\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3281\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message)\n\u001B[0;32m   3282\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot identify image file \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (filename \u001B[38;5;28;01mif\u001B[39;00m filename \u001B[38;5;28;01melse\u001B[39;00m fp)\n\u001B[1;32m-> 3283\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m UnidentifiedImageError(msg)\n",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m: cannot identify image file 'imagenet_subset\\\\bird\\\\bird_0.jpg'"
     ]
    }
   ],
   "source": [
    "image = Image.open(r\"imagenet_subset\\bird\\bird_0.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:43:34.144965800Z",
     "start_time": "2023-06-13T10:43:34.105955100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxford Pets Dataset subset downloaded and extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# Define the URL to download the Oxford Pets Dataset\n",
    "url = \"http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\"\n",
    "\n",
    "# Define the output directory to store the downloaded dataset\n",
    "output_dir = \"oxford_pets_dataset\"\n",
    "\n",
    "# Define the categories to download\n",
    "categories = [\"cats\", \"dogs\"]\n",
    "\n",
    "# Define the number of images to download per category\n",
    "num_images_per_category = 3\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "dataset_file = os.path.join(output_dir, \"images.tar.gz\")\n",
    "urllib.request.urlretrieve(url, dataset_file)\n",
    "\n",
    "# Extract the dataset for the selected categories and desired number of images\n",
    "with tarfile.open(dataset_file, \"r:gz\") as tar:\n",
    "    extracted_images = 0\n",
    "    for member in tar.getmembers():\n",
    "        if extracted_images >= len(categories) * num_images_per_category:\n",
    "            break\n",
    "\n",
    "        for category in categories:\n",
    "            if category in member.name:\n",
    "                tar.extract(member, path=output_dir)\n",
    "                extracted_images += 1\n",
    "                if extracted_images % num_images_per_category == 0:\n",
    "                    break\n",
    "\n",
    "# Remove the downloaded tarball file\n",
    "os.remove(dataset_file)\n",
    "\n",
    "print(\"Oxford Pets Dataset subset downloaded and extracted successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:50:32.041433100Z",
     "start_time": "2023-06-13T10:49:46.444482300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1: Choose pretrained image classification model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "im = Image.open(r\"turtle.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:59:37.912716Z",
     "start_time": "2023-06-13T10:59:37.665678200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-2.0837, -2.1008, -2.1008,  ..., -2.0837, -2.1008, -2.0665],\n          [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0665, -2.0837],\n          [-2.0837, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n          ...,\n          [-2.0665, -2.0837, -2.0837,  ...,  1.5810,  1.7352,  1.9235],\n          [-2.0837, -2.0837, -2.0665,  ...,  1.4612,  1.8037,  1.9064],\n          [-2.0665, -2.0665, -2.0665,  ...,  1.3755,  1.6324,  1.5468]],\n\n         [[-0.2500, -0.1625, -0.0749,  ..., -0.3200, -0.3550, -0.4076],\n          [-0.1625, -0.1275, -0.0574,  ..., -0.2850, -0.3200, -0.3725],\n          [-0.1450, -0.0749, -0.0049,  ..., -0.2850, -0.3025, -0.3200],\n          ...,\n          [-0.2675, -0.1800, -0.0224,  ...,  2.0434,  2.0259,  2.0434],\n          [-0.4426, -0.2500,  0.0126,  ...,  2.0609,  1.9559,  2.0084],\n          [-0.3901, -0.1800,  0.1001,  ...,  2.0084,  2.0084,  2.0784]],\n\n         [[ 1.1585,  1.2108,  1.3328,  ...,  1.2282,  1.1759,  1.1237],\n          [ 1.2282,  1.2805,  1.4200,  ...,  1.2282,  1.2457,  1.2282],\n          [ 1.2980,  1.3677,  1.4897,  ...,  1.2980,  1.2805,  1.2457],\n          ...,\n          [ 0.3568,  0.4265,  0.6705,  ...,  0.3568, -0.2184,  0.3219],\n          [ 0.0431,  0.2696,  0.3568,  ...,  1.2805,  0.0082,  1.1062],\n          [-0.0615,  0.2522,  0.3916,  ...,  1.3328,  0.4439,  1.9603]]]])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:05:56.207425100Z",
     "start_time": "2023-06-13T11:05:56.199421200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:59:39.424699100Z",
     "start_time": "2023-06-13T10:59:39.420182100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-2.0837, -2.1008, -2.1008,  ..., -2.0837, -2.1008, -2.0665],\n          [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0665, -2.0837],\n          [-2.0837, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n          ...,\n          [-2.0665, -2.0837, -2.0837,  ...,  1.5810,  1.7352,  1.9235],\n          [-2.0837, -2.0837, -2.0665,  ...,  1.4612,  1.8037,  1.9064],\n          [-2.0665, -2.0665, -2.0665,  ...,  1.3755,  1.6324,  1.5468]],\n\n         [[-0.2500, -0.1625, -0.0749,  ..., -0.3200, -0.3550, -0.4076],\n          [-0.1625, -0.1275, -0.0574,  ..., -0.2850, -0.3200, -0.3725],\n          [-0.1450, -0.0749, -0.0049,  ..., -0.2850, -0.3025, -0.3200],\n          ...,\n          [-0.2675, -0.1800, -0.0224,  ...,  2.0434,  2.0259,  2.0434],\n          [-0.4426, -0.2500,  0.0126,  ...,  2.0609,  1.9559,  2.0084],\n          [-0.3901, -0.1800,  0.1001,  ...,  2.0084,  2.0084,  2.0784]],\n\n         [[ 1.1585,  1.2108,  1.3328,  ...,  1.2282,  1.1759,  1.1237],\n          [ 1.2282,  1.2805,  1.4200,  ...,  1.2282,  1.2457,  1.2282],\n          [ 1.2980,  1.3677,  1.4897,  ...,  1.2980,  1.2805,  1.2457],\n          ...,\n          [ 0.3568,  0.4265,  0.6705,  ...,  0.3568, -0.2184,  0.3219],\n          [ 0.0431,  0.2696,  0.3568,  ...,  1.2805,  0.0082,  1.1062],\n          [-0.0615,  0.2522,  0.3916,  ...,  1.3328,  0.4439,  1.9603]]]])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = transform(im).unsqueeze(0)\n",
    "im"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:59:41.683832Z",
     "start_time": "2023-06-13T10:59:40.803674700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(im)\n",
    "\n",
    "# Get the top predicted classes\n",
    "_, predicted_indices = torch.topk(outputs, k=3)\n",
    "predicted_indices = predicted_indices.squeeze().tolist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:59:41.693212900Z",
     "start_time": "2023-06-13T10:59:41.227088100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageNet class labels downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Define the URL to download the ImageNet class labels\n",
    "url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "\n",
    "# Define the filename to save the class labels\n",
    "filename = \"imagenet_classes.txt\"\n",
    "\n",
    "# Download the class labels\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "print(\"ImageNet class labels downloaded successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:59:41.836511900Z",
     "start_time": "2023-06-13T10:59:41.660677900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top predicted classes:\n",
      "\"loggerhead sea turtle\",\n",
      "\"leatherback sea turtle\",\n",
      "\"terrapin\",\n"
     ]
    }
   ],
   "source": [
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(\"Top predicted classes:\")\n",
    "for index in predicted_indices:\n",
    "    print(f\"{class_names[index]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T10:59:41.837518400Z",
     "start_time": "2023-06-13T10:59:41.836511900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:02:16.045357600Z",
     "start_time": "2023-06-13T11:02:06.979504800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"turtle.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:07:24.997210Z",
     "start_time": "2023-06-13T11:07:24.955153100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# Convert the image to LAB color space\n",
    "image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:07:37.348543600Z",
     "start_time": "2023-06-13T11:07:37.329412300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.7.0.72-cp37-abi3-win_amd64.whl (44.9 MB)\n",
      "     ---------------------------------------- 44.9/44.9 MB 8.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.23.5)\n",
      "Installing collected packages: opencv-contrib-python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\User\\\\anaconda3\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'ximgproc'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpip install opencv-contrib-python\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Create the SLIC superpixel object\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m slic \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mximgproc\u001B[49m\u001B[38;5;241m.\u001B[39mcreateSuperpixelSLIC(image_lab, algorithm\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSLIC\u001B[39m\u001B[38;5;124m'\u001B[39m, region_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'cv2' has no attribute 'ximgproc'"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python\n",
    "# Create the SLIC superpixel object\n",
    "slic = cv2.ximgproc.createSuperpixelSLIC(image_lab, algorithm='SLIC', region_size=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:08:39.249748200Z",
     "start_time": "2023-06-13T11:08:27.394494100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[68], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Convert the image to RGB color space\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m image_rgb \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcvtColor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCOLOR_BGR2RGB\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Convert the image to 8-bit format\u001B[39;00m\n\u001B[0;32m     12\u001B[0m image_8bit \u001B[38;5;241m=\u001B[39m img_as_ubyte(image_rgb)\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from skimage.segmentation import slic\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"image.jpg\")\n",
    "\n",
    "# Convert the image to RGB color space\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert the image to 8-bit format\n",
    "image_8bit = img_as_ubyte(image_rgb)\n",
    "\n",
    "# Perform the superpixel segmentation\n",
    "num_segments = 100  # Number of desired superpixels\n",
    "segments = slic(image_8bit, n_segments=num_segments, compactness=10)\n",
    "\n",
    "# Create a mask for each superpixel\n",
    "mask = np.zeros_like(image)\n",
    "for label in np.unique(segments):\n",
    "    mask[segments == label] = image[segments == label]\n",
    "\n",
    "# Display the superpixel segmentation result\n",
    "cv2.imshow(\"Superpixel Segmentation\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:09:12.658718300Z",
     "start_time": "2023-06-13T11:09:10.940060900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Perform the superpixel segmentation\n",
    "slic.iterate(10)\n",
    "\n",
    "# Get the labels and number of superpixels\n",
    "labels = slic.getLabels()\n",
    "num_superpixels = slic.getNumberOfSuperpixels()\n",
    "\n",
    "# Create a mask for each superpixel\n",
    "mask = np.zeros_like(image)\n",
    "for label in np.unique(labels):\n",
    "    mask[labels == label] = image[labels == label]\n",
    "\n",
    "# Display the superpixel segmentation result\n",
    "cv2.imshow(\"Superpixel Segmentation\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
