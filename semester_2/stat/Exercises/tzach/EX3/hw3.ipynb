{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7c2837",
   "metadata": {},
   "source": [
    "#### Advanced Statistics for Data Science (Spring 2022)\n",
    "# Home Assignment 3\n",
    "#### Topics:\n",
    "- Statistical Estimation\n",
    "- Hypothesis Testing in one and two samples\n",
    "\n",
    "#### Due: 25/04/2022 by 18:30\n",
    "\n",
    "#### Instructions:\n",
    "- Write your name, Student ID, and date in the cell below. \n",
    "- Submit a copy of this notebook with code filled in the relevant places as the solution of coding excercises.\n",
    "- For theoretic excercises, you can either write your solution in the notebook using $\\LaTeX$ or submit additional notes.\n",
    "\n",
    "<hr>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972793a2",
   "metadata": {},
   "source": [
    "\n",
    "**Name**: \n",
    "\n",
    "**Student ID**:\n",
    "\n",
    "**Date**:\n",
    "\n",
    "$\n",
    "\\newcommand{\\Id}{{\\mathbf{I}}}  \n",
    "\\newcommand{\\SSE}{\\mathsf{SSE}}\n",
    "\\newcommand{\\SSR}{\\mathsf{SSR}}\n",
    "\\newcommand{\\MSE}{\\mathsf{MSE}}\n",
    "\\newcommand{\\simiid}{\\overset{iid}{\\sim}}\n",
    "\\newcommand{\\ex}{\\mathbb E}\n",
    "\\newcommand{\\var}{\\mathrm{Var}}\n",
    "\\newcommand{\\Cov}[2]{{\\mathrm{Cov}  \\left(#1, #2 \\right)}}\n",
    "\\newcommand{\\one}[1]{\\mathbf 1 {\\left\\{#1\\right\\}}}\n",
    "\\newcommand{\\SE}[1]{\\mathrm{SE} \\left[#1\\right]}\n",
    "\\newcommand{\\reals}{\\mathbb R}\n",
    "\\newcommand{\\Ncal}{\\mathcal N}\n",
    "\\newcommand{\\abs}[1]{\\ensuremath{\\left\\vert#1\\right\\vert}}\n",
    "\\newcommand{\\rank}{\\operatorname{rank}}\n",
    "\\newcommand{\\tr}{\\operatorname{Tr}}\n",
    "\\newcommand{\\diag}{\\operatorname{diag}}\n",
    "\\newcommand{\\sign}{\\operatorname{sign}}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50517ab",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1289d1-23e6-4b47-95e4-ef8304d5501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93acbbf2",
   "metadata": {},
   "source": [
    "## Problem 1 (Variance Estimation)\n",
    "\n",
    "Consider the variance estimate\n",
    "$$\n",
    "s^2 = \\frac{1}{n-1} \\sum_{i=1}^n(y_i - \\bar{y})^2. \n",
    "$$\n",
    "If $Y_i \\simiid \\Ncal(\\mu,\\sigma^2)$, then \n",
    "$$\n",
    "\\frac{n-1}{\\sigma^2}s^2 \\sim \\chi^2_{n-1}.\n",
    "$$\n",
    "1. Use this information to derive a $1-\\alpha$ coinfidence interval for $\\sigma^2$ (express $L$ and $U$ in terms of $s^2$, $n$, and the relevant quantiles of the $\\chi^2$ distribution). \n",
    "2. For $n = 2,\\ldots,10$ and $\\alpha=0.05$, report on the lower ($L$) and upper ($U$) values of the coinfidence interval in terms of $s^2$. \n",
    "3. How large $n$ must be to obtain a $0.95$ coinfidence interval of size $0.1s^2$? \n",
    "\n",
    "The point: the number of degrees of freedom needed for a reasonable ($10\\%$ range) estimate of the variance can be very large. Sometimes, much larger than our data permit.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8145013-a56e-44e9-858b-1b571fc3749c",
   "metadata": {},
   "source": [
    "### Answer\n",
    "##### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b32be-2f58-4ff9-9072-24fa3492470e",
   "metadata": {},
   "source": [
    "We know that $$\\frac{n-1}{\\sigma^2}s^2 \\sim \\chi^2_{n-1} $$\n",
    "Hence $$ \\chi^2_{1-\\frac{\\alpha}{2}} < \\frac{n-1}{\\sigma^2}s^2 < \\chi^2_\\frac{\\alpha}{2}$$\n",
    "If we clear the fractions we'll get $$ \\frac{n-1}{\\chi^2_\\frac{\\alpha}{2}} s^2 < \\sigma^2 < \\frac{n-1}{\\chi^2_{1-\\frac{\\alpha}{2}}} s^2 $$\n",
    "\n",
    "Meaning, $$L = \\frac{n-1}{\\chi^2_\\frac{\\alpha}{2}} s^2 $$\n",
    "$$U = \\frac{n-1}{\\chi^2_{1-\\frac{\\alpha}{2}}} s^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f0f4c-9b08-40af-a100-2bf5254242bc",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b4447cb-358e-4363-9fb6-be4c787e730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.linspace(2, 10, num=9)\n",
    "alpha = 0.05\n",
    "\n",
    "def get_c_i(n, alpha, should_print=False):\n",
    "    num = dof = n - 1\n",
    "    l_den = st.chi2.ppf(alpha/2, dof)\n",
    "    u_den = st.chi2.ppf(1 - alpha/2, dof)\n",
    "    if should_print:\n",
    "        print(f\"For n = {n}:\\n   L = {num/l_den:.3f} * s^2 \\n   U = {num/u_den:.3f} * s^2\")\n",
    "    return (num/l_den, num/u_den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97665e6a-2360-4ad7-bdc1-4a3f81f43805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n = 2.0:\n",
      "   L = 1018.258 * s^2 \n",
      "   U = 0.199 * s^2\n",
      "For n = 3.0:\n",
      "   L = 39.498 * s^2 \n",
      "   U = 0.271 * s^2\n",
      "For n = 4.0:\n",
      "   L = 13.902 * s^2 \n",
      "   U = 0.321 * s^2\n",
      "For n = 5.0:\n",
      "   L = 8.257 * s^2 \n",
      "   U = 0.359 * s^2\n",
      "For n = 6.0:\n",
      "   L = 6.015 * s^2 \n",
      "   U = 0.390 * s^2\n",
      "For n = 7.0:\n",
      "   L = 4.849 * s^2 \n",
      "   U = 0.415 * s^2\n",
      "For n = 8.0:\n",
      "   L = 4.142 * s^2 \n",
      "   U = 0.437 * s^2\n",
      "For n = 9.0:\n",
      "   L = 3.670 * s^2 \n",
      "   U = 0.456 * s^2\n",
      "For n = 10.0:\n",
      "   L = 3.333 * s^2 \n",
      "   U = 0.473 * s^2\n"
     ]
    }
   ],
   "source": [
    "for n in ns:\n",
    "    get_c_i(n, alpha, should_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010e240-3ad0-4298-b3d2-a40d481ec5a5",
   "metadata": {},
   "source": [
    "#### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b967c1a0-cf33-40b8-8deb-c0375d17a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To obstain a cofidence interval in the size of 0.1*s^2, we need to have at least 3082 samples\n"
     ]
    }
   ],
   "source": [
    "ns = np.array(range(2,1_000_000))\n",
    "for n in ns:\n",
    "    l,u = get_c_i(n, alpha)\n",
    "    if abs(l-u) <= 0.1:\n",
    "        print(f\"To obstain a cofidence interval in the size of 0.1*s^2, we need to have at least {n} samples\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e3f051",
   "metadata": {},
   "source": [
    "## Problem 2 (Correlated Data)\n",
    "\n",
    "Suppose that $Y_1,\\ldots,Y_n$ has each mean $\\mu$ and variance $\\sigma^2$, but \n",
    "$$\n",
    "\\rho_{ij} := \\mathrm{Corr}(Y_i,Y_j) = \\begin{cases}\n",
    "1 & i=j \\\\\n",
    "\\rho & |i-j| = 1 \\\\\n",
    "0 & |i-j| > 1\n",
    "\\end{cases}.\n",
    "$$\n",
    "This situation arise when an observation $i$ may depend to some extent on only the previous observation’s white noise: an one-lag \"holdeover effect\". This is also known as the \"lag-1 moving average\" model (MA(1)). \n",
    "\n",
    "1. Show that:\n",
    "  - $$\\mathrm{Var}(\\bar{Y}) = \\frac{\\sigma^2}{n}(1+ 2\\rho \\frac{n-1}{n})$$\n",
    "Namely, positive correlation increases varaince. Hint: use that $\\mathrm{Var}(U+V) = \\mathrm{Var}(U) + \\mathrm{Var}(V) + 2 \\mathrm{Cov}(U,V)$ and induction or recursive computation over $n$. Another option is to write $Y = \\Sigma^{1/2}Z$ where $Z\\sim \\Ncal(0,I)$ and $\\Sigma^{1/2}$ is symmetric with  $\\Sigma^{1/2}\\Sigma^{1/2} = \\Sigma$ has the desired covariance stracture.  \n",
    "\n",
    "  - $$\\qquad \\ex[{s^2}] = \\sigma^2(1 - 2\\rho/n)$$\n",
    "  where $s^2$ is the standard varince estiamte. \n",
    "Namely, with positive correlation the \"variety\" in the data is smaller. \n",
    "\n",
    "  - **(Bonus)** The t-statistic statisfies\n",
    "$$\n",
    "t = \\sqrt{n} \\frac{\\bar{Y}-\\mu}{s} \\to \\Ncal(0,1 + 2 \\rho),\\quad n \\to \\infty\n",
    "$$\n",
    "Hint: you may use the following version of Slutsky's Theorem: for two sequences of RV U_n and V_n, if $U_n \\overset{D}{\\to} U$ and $V_n \\overset{p}{\\to} c$ (constant), then $ V_n U_n \\overset{D}{\\to} cU$\n",
    "2. Verify your answer to the first two items in 1 using simulations. Use `nMonte = 10000` problem instances. In each instance, use a sample size of `n = 10` with $\\sigma=1$ and $\\rho \\in \\{\\pm 0.1, \\pm 0.3, \\pm0.5\\}$. The function `genrate_correlated_data` below generates noramlly distributed data satisfying the correlation model above. \n",
    "\n",
    "3. Suppose $\\rho>0$\n",
    " - Derive a $1-\\alpha$ confidence interval based on $s$ and the $t$-distribution with $n-1$ DoF. Does your interval \n",
    " contains the value of $\\mu$ more or less often than $1-\\alpha$? Verify using a simulation with `nMonte = 10000` problem instances of sampes size `n=100`. Also use $\\alpha=0.05$, $\\rho=.25$, $\\sigma =1$, and $\\mu_0=2$. \n",
    " \n",
    " - Suppose that we reject $H_0\\,:\\,\\mu = \\mu_0$ whenever $t$ exceeds the critical value $t_{n-1}^{1-\\alpha/2}$. Would our P-value be too small or too large? Would we reject more or less often then $\\alpha$ if the null $\\mu = \\mu_0$ is true? Verify using a simulation with `nMonte = 10000` problem instances of sampes size `n=100`. Also use $\\alpha=0.05$, $\\rho=.25$, $\\sigma =1$, and $\\mu_0=2$. \n",
    " \n",
    " - Would your answer to the preivous two items change if $\\rho < 0$? how?\n",
    "\n",
    "The point: correlation in our data is bad because it makes us make wrong descisions. The effect of correlation is much worst than non-nomrality since the latter diminishes with $n$ due to the CLT. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03b95b-4874-49f2-84ad-a9510f12d561",
   "metadata": {},
   "source": [
    "### Answer\n",
    "##### Part 1\n",
    "\n",
    "\n",
    "1. Show that:\n",
    "  - $$\\mathrm{Var}(\\bar{Y}) = \\frac{\\sigma^2}{n}(1+ 2\\rho \\frac{n-1}{n})$$\n",
    "Namely, positive correlation increases varaince. Hint: use that $\\mathrm{Var}(U+V) = \\mathrm{Var}(U) + \\mathrm{Var}(V) + 2 \\mathrm{Cov}(U,V)$ and induction or recursive computation over $n$. Another option is to write $Y = \\Sigma^{1/2}Z$ where $Z\\sim \\Ncal(0,I)$ and $\\Sigma^{1/2}$ is symmetric with  $\\Sigma^{1/2}\\Sigma^{1/2} = \\Sigma$ has the desired covariance stracture.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cad765-d883-4d1e-a3bf-b39c3e223631",
   "metadata": {},
   "source": [
    "We know that if $[Y_1, Y_2,...,Y_n]$ are $iid$ then $$Var(\\hat{Y}) = \\frac{\\sigma^2}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6baf4b-356f-429b-9771-8f2e99ff4822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bcfcf0-add5-4da8-869d-24eb083ee3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e4620-9744-4748-9250-87e8c3f777ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc3209-128a-4f77-8407-0498ed00d57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210ea7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrate_correlated_data(n: int, rho: float, mu: float, sigma: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate samples from the model:\n",
    "    Yi ~ N(mu, sigma^2) and Corr(Yi,Yj) = ( i == j ) + rho * ( abs( i - j ) == 1 )\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "    :n:     sample size\n",
    "    :rho:   desired one lag correlation between samples\n",
    "    :mu:    mean\n",
    "    :sigma: standard deviation\n",
    "    \n",
    "    \"\"\"\n",
    "    assert sigma > 0\n",
    "    \n",
    "    # build desired covariance matrix\n",
    "    Sig = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i==j : \n",
    "                Sig[i,j] = 1\n",
    "            if np.abs(i-j) == 1:\n",
    "                Sig[i,j] = rho\n",
    "                Sig[j,i] = rho\n",
    "                \n",
    "    # get matrix square root of covariance matrix:\n",
    "    Sig_sqrt = np.linalg.cholesky(sigma**2 * Sig)\n",
    "    \n",
    "    # sample from the standard normal dist. and transform \n",
    "    # so that the result is a normal vector with the desired \n",
    "    # covaraince structure\n",
    "    return mu + Sig_sqrt @ np.random.randn(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581e1ca",
   "metadata": {},
   "source": [
    "## Problem 3 (Regression and Hypothesis Testing)\n",
    "\n",
    "The dataset for this problem is available in the file temp_TLV_beach.csv, which was taken directly from the meterological service website (https://ims.data.gov.il/ims/1). \n",
    "\n",
    "We consider monitoring changes in rainfall/precipitation over the years at Station 136320 located at Tel-Aviv beach area. \n",
    "To do so, we will set up a standard linear model with $p = 3$ features, where for dates (times) $t \\in \\{0,1,\\ldots,366\\}$ (we have 366 for leap years) we set\n",
    "$$\n",
    "y_t = \\beta_0 + \\beta_1 \\cos( 2\\pi(t/365)) + \\beta_2 \\sin( 2\\pi(t/365)) + \\epsilon_t,\\qquad t=1,\\ldots,n. \n",
    "\\label{eq:model} \\tag{2}\n",
    "$$\n",
    "(note that the dataset does not contain measurments from all days in the range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c92dbd",
   "metadata": {},
   "source": [
    "1) Set $y_t = \\texttt{Rainfall}$. \n",
    " - Plot $y_t$ versus $t=$`Date` and identify winter times.\n",
    "\n",
    "- Find the LS regression coefficients $\\beta$; plot the fitted response $\\hat{y}_t$ over time along with the original response $y_t$. \n",
    "\n",
    " - Test whether the fitted model significantly improves on the trival model $y_t = \\beta'_0 + \\epsilon_t$.\n",
    " \n",
    " - For each parameter $p$, report the P-value for testing $H_0\\,:\\,\\hat{\\beta}_p = 0$ and indicate whether this parameter is \n",
    "significantly different than $0$ at level $\\alpha = 0.01$. \n",
    "(for this item, you can either evaluate everything from the formulas provded in class or use a statistical package like `statsmodels`)\n",
    "\n",
    "You may use the code below to format the `Date` column correctly and extract other relevant information from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dde4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_data_file = \"../data/01_raw/rainfall_TLV_beach.csv\"\n",
    "data = pd.read_csv(path_to_data_file)\n",
    "\n",
    "data['Date'] = pd.to_datetime(data.Date, format=\"%d-%m-%Y\")\n",
    "data['DayOfYear'] = data.Date.dt.day_of_year\n",
    "data['Month'] = data.Date.dt.month\n",
    "data['Year'] = data.Date.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7343c68",
   "metadata": {},
   "source": [
    "2) We would like to test whether future data follows a similar distribution to past data. Consider two datasets modeled by\n",
    "$$\n",
    "\\begin{equation}\n",
    "y = Z \\beta + \\epsilon,\\qquad y_{new} = Z_{new} \\beta + \\epsilon_{new}\n",
    "\\label{eq:model} \\tag{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "where $Z \\in \\reals^{m\\times p}$ and $Z_{new} \\in \\reals^{n\\times p}$ are the given design matrices which both assume to have rank $p$. We also assume that $\\epsilon$ and $\\epsilon_{new}$ are independent. We will think of $(Z, y)$ as the initial data pair and $(Z_{new},y_{new})$ as the new data.\n",
    "\n",
    "Let $\\hat{\\beta} = (Z \\top Z)^{-1}Z^\\top y$ be the usual least-squares (LS) estimate on the initial data. Define the predicted values as\n",
    " $$\n",
    " \\hat{y}_{new} := Z_{new} \\hat{\\beta}\n",
    " $$\n",
    " (note that $\\hat{y}_{new}$ is not the LS estiamte of $y_{new}$ from $Z_{new}$)\n",
    " \n",
    " - Show that $\\mathrm{Cov}(y-\\hat{y},y_{new} - \\hat{y}_{new})=0$\n",
    " \n",
    " - Assume $\\epsilon_{new} \\sim \\Ncal(0,\\sigma^2 I_n)$. Find a (symmetric, positive definite) matrix $M \\in \\reals^{n \\times n}$ so that\n",
    " $$\n",
    " M(y_{new} - \\hat{y}_{new}) \\sim \\Ncal(0, \\sigma^2 I_n).\n",
    " $$\n",
    " \n",
    "- Give the distribution of the ratio\n",
    "$$\n",
    "\\begin{equation}\n",
    "A:= \\frac{\\frac{1}{n}\\left\\| M(Y_{new} - \\hat{Y}_{new})\\right\\|^2}{\\frac{1}{m-d} \\left\\| Y  - \\hat{Y} \\right\\|^2 }\n",
    "\\label{eq:A} \\tag{3}\n",
    "\\end{equation}\n",
    "$$\n",
    "under the null hypothesis:\n",
    "$$\n",
    "H_0\\,:\\,\\begin{cases} Y = Z \\beta + \\epsilon,\\qquad Y_{new} = Z_{new} \\beta + \\epsilon_{new} \\\\\n",
    "\\epsilon \\sim \\Ncal(0, \\sigma^2 I_m),\\qquad \\epsilon_{new} \\sim \\Ncal(0, \\sigma^2 I_n) \\\\\n",
    "\\text{$\\epsilon$ and $\\epsilon_{new}$ are independent}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We now consider implementing a series of hypothesis tests about whether daily rainfall is remaining consistent over the years or whether it is changing in some meaningful way. \n",
    "\n",
    "- For each of the years 2010, 2011,...,2021, repeat the following. Define a data matrix $Z$ using the features in $\\eqref{eq:model}$ consisting of all dates prior to that year (so that for 2010, $Z$ will be\n",
    "a data matrix for the years 2005–2009, for 2011, $Z$ will be the data for years 2005-2011, and\n",
    "so on). Define the responses $y$ to consist of rainfall for the given years. Define the new data matrix $Z_{new} \\in \\reals^{n \\times p}$ to consist of the $n$ days of measurements in the given year ($n\\leq 366$) and the responses $y_{new}$ to be the rainfall in those days. For this data, compute the statistic $A$ in $\\eqref{eq:A}$ and its p-value, that is, conditional on\n",
    "$A = a$, report\n",
    "$$\n",
    "p := \\Pr[A \\geq a] \\quad \\text{under $H_0$}\n",
    "$$\n",
    "Plot the P-values for each of the years and also print their values. Discuss briefly. \n",
    "- Suppose that you obtained a very small p-value of some year, say $p \\approx 10^{-5}$. Does rejecting the null hypothesis necessarily mean that the distribution of rainfall is changing over time? explain in 2-3 sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb1005",
   "metadata": {},
   "source": [
    "3) Consider the total amount of rainfall within each month. Suppose that we assume that there is no change in the distribution over time across years, but we suspect that December is usuallly rainier than February. Design a test procedure that checks whether this is true. Use two apporaches:\n",
    " - Two-sample t-test \n",
    " - Paired t-test \n",
    " - Which approach seems more approproate here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71df9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
